{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import scipy.misc\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscNet(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, ndf = 64, ngpu = 1):\n",
    "        super(DiscNet, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.ndf = ndf\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            #Start with (N x 1 x input_size x input_size) 32\n",
    "            nn.Conv2d(self.in_dim, self.ndf, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Gives me (N x ndf x input_size//2 x input_size//2) 16\n",
    "            nn.Conv2d(self.ndf, self.ndf*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Then have N x 2*ndf x input_size//4 x input_size//4 8\n",
    "            nn.Conv2d(self.ndf*2, self.ndf*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Now have N x 4*ndf x input_size//8 x input_size//8 4\n",
    "            nn.Conv2d(self.ndf*4, self.ndf*8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf*8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Now N x 8*ndf x input_size//16 x input_size//16 2\n",
    "            nn.Conv2d(self.ndf*8, self.out_dim, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "            #Output N x out_dim x 2 x 2\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.conv(inp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenNet(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, ngf = 64, ngpu = 1):\n",
    "        super(GenNet, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.ngf = ngf\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            #start with latent dimensional input\n",
    "            nn.ConvTranspose2d(self.in_dim, 4 * self.ngf, 4, 1, 0),\n",
    "            nn.BatchNorm2d(4*self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #Now 100 x 4*ngf x 4 x 4\n",
    "            nn.ConvTranspose2d(4*self.ngf, 2*self.ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2*self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #Now 100 x 2*ngf x 8 x 8\n",
    "            nn.ConvTranspose2d(2*self.ngf, self.ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #Now 100 x ngf x 16 x 16\n",
    "            nn.ConvTranspose2d(self.ngf, self.out_dim, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "            #Output 100 x out_dim (num_channels) x 32 x 32 images.\n",
    "        )\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return self.conv(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self):\n",
    "        self.num_epochs = 100\n",
    "        self.batch_size = 128\n",
    "        self.image_size = 32\n",
    "        self.z_dim = 100\n",
    "        self.ndf = 32\n",
    "        self.ngf = 32\n",
    "        self.lr = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.999\n",
    "        \n",
    "        self.ngpu = 1\n",
    "        self.dataset = 'MNIST'\n",
    "        self.save_dir = 'models/'\n",
    "        self.result_dir = 'results/'\n",
    "        self.model_name = 'DCGAN'\n",
    "        self.sample_num = 100\n",
    "        self.num_workers = 2\n",
    "        \n",
    "        #NOTE: Change the normalization if not using MNIST.\n",
    "        trans = transforms.Compose([\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.CenterCrop(self.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (.1307, ), std = (0.3081, ))\n",
    "        ])\n",
    "        \n",
    "        self.data_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(root = './data', train = True, download = True, transform = trans),\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = self.num_workers\n",
    "        )\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "        self.num_channels = data.size()[1]\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and self.ngpu >0) else \"cpu\")\n",
    "        \n",
    "        \n",
    "        self.D = DiscNet(in_dim = self.num_channels, out_dim = 1, ndf = self.ndf , ngpu = self.ngpu)\n",
    "        self.G = GenNet(in_dim = self.z_dim, out_dim = self.num_channels, ngf = self.ngf, ngpu = self.ngpu)\n",
    "        \n",
    "        self.G = self.G.to(self.device)\n",
    "        self.D = self.D.to(self.device)\n",
    "        \n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.sample_z = torch.randn(self.batch_size, self.z_dim, 1, 1, device = self.device)\n",
    "        \n",
    "        if (self.device.type == 'cuda') and (self.ngpu > 1):\n",
    "            self.G = nn.DataParallel(self.G, list(range(self.ngpu)))\n",
    "            self.D = nn.DataParallel(self.D, list(range(self.ngpu)))\n",
    "        \n",
    "        self.G.apply(self.weights_init)\n",
    "        self.D.apply(self.weights_init)\n",
    "        \n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr = self.lr, betas = (self.beta1, self.beta2))\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr = self.lr, betas = (self.beta1, self.beta2))\n",
    "\n",
    "        \n",
    "    def plot_train(self):\n",
    "        real_batch = next(iter(self.data_loader))\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Training Images\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(self.device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "    \n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    \n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['per_epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "        \n",
    "        real_label = 1\n",
    "        fake_label = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            for i, data in enumerate(self.data_loader, 0):\n",
    "                \n",
    "                #TRAIN D\n",
    "                self.D.zero_grad()\n",
    "                real_im = data[0].to(self.device)\n",
    "                b_size = real_im.size(0)\n",
    "                label = torch.full((b_size, ), real_label, device = self.device)\n",
    "                \n",
    "                output = self.D(real_im).view(-1)\n",
    "#                 print(output.size(), label.size())\n",
    "                D_real_loss = self.criterion(output, label)\n",
    "                D_real_loss.backward()\n",
    "                D_x = output.mean().item()\n",
    "                \n",
    "                noise = torch.randn(b_size, self.z_dim, 1, 1, device = self.device)\n",
    "                fake = self.G(noise)\n",
    "                label.fill_(fake_label)\n",
    "                output = self.D(fake.detach()).view(-1)\n",
    "                D_fake_loss = self.criterion(output, label)\n",
    "                D_fake_loss.backward()\n",
    "                \n",
    "                D_G_z1 = output.mean().item()\n",
    "                \n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "                self.D_optimizer.step()\n",
    "                \n",
    "                #Train G\n",
    "                self.G.zero_grad()\n",
    "                label.fill_(real_label)\n",
    "                output = self.D(fake).view(-1)\n",
    "                G_loss = self.criterion(output, label)\n",
    "                \n",
    "                G_loss.backward()\n",
    "                G_G_z2 = output.mean().item()\n",
    "                self.G_optimizer.step()\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "                \n",
    "                self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
    "                \n",
    "            self.train_hist['total_time'].append(time.time() - start_time)\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "            print(\"Completed epoch {}\".format(epoch+1))\n",
    "        \n",
    "        print(\"Done Training!\")\n",
    "        self.save()\n",
    "        \n",
    "        \n",
    "        generate_animation('{}/{}/{}/{}'.format(self.result_dir, self.dataset, self.model_name, self.model_name),\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        \n",
    "        \n",
    "    def visualize_results(self, epoch, fix=True):\n",
    "        self.G.eval()\n",
    "        \n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "            \n",
    "        tot_num_samples = min(self.sample_num, self.batch_size)\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "        \n",
    "        samples = self.G(self.sample_z)\n",
    "        \n",
    "        if self.ngpu>0:\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "            \n",
    "        samples = (samples + 1)/2\n",
    "        \n",
    "        \n",
    "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], \n",
    "                    [image_frame_dim, image_frame_dim],\n",
    "        '{}/{}/{}/{}_epoch{:03}.png'.format(self.result_dir, self.dataset, self.model_name, self.model_name, epoch))\n",
    "        \n",
    "    \n",
    "    def save(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
    "        \n",
    "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.train_hist, f)\n",
    "    \n",
    "    def load(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "        \n",
    "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 1\n",
      "Completed epoch 2\n",
      "Completed epoch 3\n",
      "Completed epoch 4\n",
      "Completed epoch 5\n",
      "Completed epoch 6\n",
      "Completed epoch 7\n",
      "Completed epoch 8\n",
      "Completed epoch 9\n",
      "Completed epoch 10\n",
      "Completed epoch 11\n",
      "Completed epoch 12\n",
      "Completed epoch 13\n",
      "Completed epoch 14\n",
      "Completed epoch 15\n",
      "Completed epoch 16\n",
      "Completed epoch 17\n",
      "Completed epoch 18\n",
      "Completed epoch 19\n",
      "Completed epoch 20\n",
      "Completed epoch 21\n",
      "Completed epoch 22\n",
      "Completed epoch 23\n",
      "Completed epoch 24\n",
      "Completed epoch 25\n",
      "Completed epoch 26\n",
      "Completed epoch 27\n",
      "Completed epoch 28\n",
      "Completed epoch 29\n",
      "Completed epoch 30\n",
      "Completed epoch 31\n",
      "Completed epoch 32\n",
      "Completed epoch 33\n",
      "Completed epoch 34\n",
      "Completed epoch 35\n",
      "Completed epoch 36\n",
      "Completed epoch 37\n",
      "Completed epoch 38\n",
      "Completed epoch 39\n",
      "Completed epoch 40\n",
      "Completed epoch 41\n",
      "Completed epoch 42\n",
      "Completed epoch 43\n",
      "Completed epoch 44\n",
      "Completed epoch 45\n",
      "Completed epoch 46\n",
      "Completed epoch 47\n",
      "Completed epoch 48\n",
      "Completed epoch 49\n",
      "Completed epoch 50\n",
      "Completed epoch 51\n",
      "Completed epoch 52\n",
      "Completed epoch 53\n",
      "Completed epoch 54\n",
      "Completed epoch 55\n",
      "Completed epoch 56\n",
      "Completed epoch 57\n",
      "Completed epoch 58\n",
      "Completed epoch 59\n",
      "Completed epoch 60\n",
      "Completed epoch 61\n",
      "Completed epoch 62\n",
      "Completed epoch 63\n",
      "Completed epoch 64\n",
      "Completed epoch 65\n",
      "Completed epoch 66\n",
      "Completed epoch 67\n",
      "Completed epoch 68\n",
      "Completed epoch 69\n",
      "Completed epoch 70\n",
      "Completed epoch 71\n",
      "Completed epoch 72\n",
      "Completed epoch 73\n",
      "Completed epoch 74\n",
      "Completed epoch 75\n",
      "Completed epoch 76\n",
      "Completed epoch 77\n",
      "Completed epoch 78\n",
      "Completed epoch 79\n",
      "Completed epoch 80\n",
      "Completed epoch 81\n",
      "Completed epoch 82\n",
      "Completed epoch 83\n",
      "Completed epoch 84\n",
      "Completed epoch 85\n",
      "Completed epoch 86\n",
      "Completed epoch 87\n",
      "Completed epoch 88\n",
      "Completed epoch 89\n",
      "Completed epoch 90\n",
      "Completed epoch 91\n",
      "Completed epoch 92\n",
      "Completed epoch 93\n",
      "Completed epoch 94\n",
      "Completed epoch 95\n",
      "Completed epoch 96\n",
      "Completed epoch 97\n",
      "Completed epoch 98\n",
      "Completed epoch 99\n",
      "Completed epoch 100\n",
      "Done Training!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GAN' object has no attribute 'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fe9c27acc7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_GAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_GAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-52ff01084a99>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         generate_animation('{}/{}/{}/{}'.format(self.result_dir, self.dataset, self.model_name, self.model_name),\n\u001b[0;32m--> 142\u001b[0;31m                                  self.epoch)\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mloss_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GAN' object has no attribute 'epoch'"
     ]
    }
   ],
   "source": [
    "my_GAN = GAN()\n",
    "my_GAN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
