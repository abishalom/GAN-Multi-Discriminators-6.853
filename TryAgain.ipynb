{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import scipy.misc\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscNet(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, ndf = 128, ngpu = 1):\n",
    "        super(DiscNet, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.ndf = ndf\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            #Start with (N x 1 x input_size x input_size) 64\n",
    "            nn.Conv2d(self.in_dim, self.ndf, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Gives me (N x ndf x input_size//2 x input_size//2) 32\n",
    "            nn.Conv2d(self.ndf, self.ndf*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Then have N x 2*ndf x input_size//4 x input_size//4 16\n",
    "            nn.Conv2d(self.ndf*2, self.ndf*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #Now have N x 4*ndf x input_size//8 x input_size//8 8\n",
    "            nn.Conv2d(self.ndf*4, self.ndf*8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf*8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            #Now N x 8*ndf x input_size//16 x input_size//16 (128 x 1024 x 4 x 4)\n",
    "#             nn.Conv2d(self.ndf*8, self.out_dim, 4, 1, 0),\n",
    "            nn.Conv2d(self.ndf*8, self.out_dim, 4, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "            #Output N x out_dim x \n",
    "        )\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        x = self.conv(inp)\n",
    "        print(x.size())\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenNet(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, ngf = 128, ngpu = 1):\n",
    "        super(GenNet, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.ngf = ngf\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            #start with latent dimensional input\n",
    "            nn.ConvTranspose2d(self.in_dim, 8*self.ngf, 4, 1, 0),\n",
    "            nn.BatchNorm2d(8*self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #100 x 8*ngf x 2 x 2\n",
    "            nn.ConvTranspose2d(8*self.ngf, 4 * self.ngf, 4, 1, 0),\n",
    "            nn.BatchNorm2d(4*self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #Now 100 x 4*ngf x 4 x 4\n",
    "            nn.ConvTranspose2d(4*self.ngf, 2*self.ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2*self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #Now 100 x 2*ngf x 8 x 8\n",
    "            nn.ConvTranspose2d(2*self.ngf, self.ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(),\n",
    "            #Now 100 x ngf x 16 x 16\n",
    "            nn.ConvTranspose2d(self.ngf, self.out_dim, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "            #Output 100 x out_dim (num_channels) x 32 x 32 images.\n",
    "        )\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return self.conv(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1024, 4, 4])\n",
      "torch.Size([128, 1024, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 1, 1]), torch.Size([128]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 64\n",
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Scale(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, ), std=(0.5,))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "D = DiscNet(1, 1, 128)\n",
    "\n",
    "x = train_loader.__iter__().__next__()[0]\n",
    "\n",
    "D(x).size(), D(x).view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self):\n",
    "        self.num_epochs = 20\n",
    "        self.batch_size = 128\n",
    "        self.image_size = 64\n",
    "        self.z_dim = 100\n",
    "        self.ndf = 128\n",
    "        self.ngf = 128\n",
    "        self.lr = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.999\n",
    "        \n",
    "        self.ngpu = 2\n",
    "        self.dataset = 'MNIST'\n",
    "        self.save_dir = 'models/'\n",
    "        self.result_dir = 'results/'\n",
    "        self.model_name = 'DCGAN'\n",
    "        self.sample_num = 25\n",
    "        self.num_workers = 2\n",
    "        \n",
    "        #NOTE: Change the normalization if not using MNIST.\n",
    "        trans = transforms.Compose([\n",
    "#             transforms.Resize(self.image_size),\n",
    "#             transforms.CenterCrop(self.image_size),\n",
    "            transforms.Scale(self.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "#             transforms.Normalize(mean = (.1307, ), std = (0.3081, ))\n",
    "        ])\n",
    "        \n",
    "        self.data_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(root = './data', train = True, download = True, transform = trans),\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = self.num_workers\n",
    "        )\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "        self.num_channels = data.size()[1]\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and self.ngpu >0) else \"cpu\")\n",
    "        \n",
    "        \n",
    "        self.D = DiscNet(in_dim = self.num_channels, out_dim = 1, ndf = self.ndf , ngpu = self.ngpu)\n",
    "        self.G = GenNet(in_dim = self.z_dim, out_dim = self.num_channels, ngf = self.ngf, ngpu = self.ngpu)\n",
    "        \n",
    "        self.G = self.G.to(self.device)\n",
    "        self.D = self.D.to(self.device)\n",
    "        \n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.sample_z = torch.randn(self.batch_size, self.z_dim, 1, 1, device = self.device)\n",
    "        \n",
    "        if (self.device.type == 'cuda') and (self.ngpu > 1):\n",
    "            self.G = nn.DataParallel(self.G, list(range(self.ngpu)))\n",
    "            self.D = nn.DataParallel(self.D, list(range(self.ngpu)))\n",
    "        \n",
    "        self.G.weight_init(mean=0., std= 0.02)\n",
    "        self.D.weight_init(mean=0., std= 0.02)\n",
    "        \n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr = self.lr, betas = (self.beta1, self.beta2))\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr = self.lr, betas = (self.beta1, self.beta2))\n",
    "\n",
    "        \n",
    "    def plot_train(self):\n",
    "        real_batch = next(iter(self.data_loader))\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Training Images\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(self.device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['per_epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "        \n",
    "        real_label = 1\n",
    "        fake_label = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            for i, (x, _) in enumerate(self.data_loader, 0):\n",
    "                \n",
    "                #TRAIN D\n",
    "                self.D.zero_grad()\n",
    "                \n",
    "                b_size = x.size()[0]\n",
    "                x = Variable(x.to(self.device))\n",
    "                y_real = Variable(torch.ones(b_size).to(self.device))\n",
    "                y_fake = Variable(torch.zeros(b_size).to(self.device))\n",
    "                \n",
    "#                 real_im = x.to(self.device)\n",
    "#                 b_size = real_im.size()[0]\n",
    "#                 label = torch.full((b_size, ), real_label, device = self.device)\n",
    "                \n",
    "                output = self.D(x).view(-1)\n",
    "#                 print(self.D(real_im).size(), output.size(), y_real.size())\n",
    "                D_real_loss = self.criterion(output, y_real)\n",
    "                \n",
    "                noise = Variable(torch.randn(b_size, self.z_dim, 1, 1, device = self.device))\n",
    "                fake = self.G(noise)\n",
    "#                 label.fill_(fake_label)\n",
    "                output = self.D(fake).view(-1)\n",
    "                D_fake_loss = self.criterion(output, y_fake)\n",
    "                                \n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "                \n",
    "                #Train G\n",
    "                self.G.zero_grad()\n",
    "#                 label.fill_(real_label)\n",
    "                noise = Variable(torch.randn(b_size, self.z_dim, 1, 1, device = self.device))\n",
    "                fake = G(noise)\n",
    "                \n",
    "                output = self.D(fake).view(-1)\n",
    "                G_loss = self.criterion(output, y_real)\n",
    "                \n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "                \n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "                \n",
    "                self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
    "                \n",
    "            self.train_hist['total_time'].append(time.time() - start_time)\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "            print(\"Completed epoch {}\".format(epoch+1))\n",
    "        \n",
    "        print(\"Done Training!\")\n",
    "        self.save()\n",
    "        \n",
    "        \n",
    "        generate_animation('{}/{}/{}/{}'.format(self.result_dir, self.dataset, self.model_name, self.model_name),\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        \n",
    "        \n",
    "    def visualize_results(self, epoch, fix=True):\n",
    "        self.G.eval()\n",
    "        \n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "            \n",
    "        tot_num_samples = min(self.sample_num, self.batch_size)\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "        \n",
    "        samples = self.G(self.sample_z)\n",
    "        \n",
    "        if self.ngpu>0:\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "            \n",
    "        samples = (samples + 1)/2\n",
    "        \n",
    "        \n",
    "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], \n",
    "                    [image_frame_dim, image_frame_dim],\n",
    "        '{}/{}/{}/{}_epoch{:03}.png'.format(self.result_dir, self.dataset, self.model_name, self.model_name, epoch))\n",
    "        \n",
    "    \n",
    "    def save(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
    "        \n",
    "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.train_hist, f)\n",
    "    \n",
    "    def load(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "        \n",
    "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid device id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-fe9c27acc7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_GAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmy_GAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-65f8df33d19a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, device_ids, output_device, dim)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0m_check_balance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36m_check_balance\u001b[0;34m(device_ids)\u001b[0m\n\u001b[1;32m     16\u001b[0m     environment variable.\"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0mdevice_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdev_props\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarn_imbalance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     environment variable.\"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0mdevice_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdev_props\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarn_imbalance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid device id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid device id"
     ]
    }
   ],
   "source": [
    "my_GAN = GAN()\n",
    "my_GAN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
