{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our notebook for 6.853 project. Our goal is to reduce mode-collapse when training GANs. We aim to do this by using existing literature on multiplayer, zero-sum games to phrase the GAN problem as a polymatrix game. Then, we aim to use the reduction to the high-stakes lawyer game. \n",
    "\n",
    "Credit for portions of the code to Github user znxlwm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import scipy.misc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS FUNCTIONS FROM UTIL\n",
    "%run Utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the MNIST dataset and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "batch_size = 100\n",
    "\n",
    "trans = transforms.Compose(\n",
    "            [transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.1307, ), std = (0.3081,))\n",
    "            ])\n",
    "                \n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "               datasets.MNIST(root = './data', train=True, download = True, transform = trans), \n",
    "               batch_size = batch_size, \n",
    "               shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data_loader.__iter__().__next__()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next step: make use convolutions isntead of flattened image.\n",
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    #Discriminator class. Outputs whehter it thinks the image is original or not.\n",
    "    def __init__(self, in_dim, out_dim, input_size):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        self.in_dim = in_dim \n",
    "        self.out_dim = out_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.in_dim, 64, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_size//4) * (self.input_size//4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, self.out_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "#         self.hidden0 = nn.Sequential(\n",
    "#             nn.Linear(self.in_dim, 1024),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "#         self.hidden1 = nn.Sequential(\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "#         self.hidden2 = nn.Sequential(\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "#         self.out = nn.Sequential(\n",
    "#             torch.nn.Linear(256, self.out_dim),\n",
    "#             torch.nn.Sigmoid()\n",
    "#         )\n",
    "    \n",
    "    def forward(self, inp):\n",
    "#         x = self.hidden0(x)\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.out(x)\n",
    "        x = self.conv(inp)\n",
    "#         print(x.size())\n",
    "        x = x.view( -1, 128 * (self.input_size // 4) * (self.input_size // 4))\n",
    "#         print(x.size())\n",
    "        x = self.fc_layer(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next step: make use convolutions instead of taking in flattened photo.\n",
    "class GeneratorNet(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, input_size):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 128 * (self.input_size // 4)**2 ),\n",
    "            nn.BatchNorm1d(128 * (self.input_size//4)**2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, self.out_dim, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "#         self.hidden0 = nn.Sequential(\n",
    "#             nn.Linear(self.in_dim, 256),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.hidden1 = nn.Sequential(\n",
    "#             nn.Linear(256, 512),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.hidden2 = nn.Sequential(\n",
    "#             nn.Linear(512, 1024),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.out = nn.Sequential(\n",
    "#             nn.Linear(1024, self.out_dim),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = self.hidden0(x)\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.out(x)\n",
    "#         print(\"IN: {}\".format(x.size()))\n",
    "        x = self.fc_layer(x)\n",
    "#         print(\"FC: {}\".format(x.size()))\n",
    "        x = x.view(-1, 128, (self.input_size//4), (self.input_size//4))\n",
    "        x = self.deconv(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the initial design with flattened images. Still learning how to use pytorch\n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, input_size, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 9, 4, 2, 0, 1, 7, 3, 1, 3, 2, 8, 3, 9, 2, 0, 0, 2, 9, 4, 7, 1, 1,\n",
      "        5, 7, 9, 0, 0, 0, 4, 4, 7, 0, 0, 5, 2, 0, 3, 4, 9, 1, 0, 7, 0, 7, 4, 0,\n",
      "        2, 9, 4, 9, 2, 2, 0, 6, 3, 4, 0, 2, 8, 8, 8, 2, 8, 5, 9, 3, 6, 2, 2, 5,\n",
      "        1, 6, 0, 1, 7, 3, 4, 1, 1, 9, 0, 5, 9, 3, 9, 5, 4, 1, 4, 5, 8, 2, 3, 7,\n",
      "        7, 9, 2, 5])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = data_loader.__iter__().__next__()\n",
    "# print(x)\n",
    "print(b)\n",
    "print(a.size())\n",
    "\n",
    "x = a.view(-1, 28*28)\n",
    "x.size()\n",
    "\n",
    "a.shape[1]\n",
    "# x = x.view(-1, 28*28)\n",
    "# z = torch.rand((self.batch_size, self.z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self):\n",
    "        self.epoch = 100\n",
    "        self.sample_num = 100\n",
    "        self.gpu_mode = True\n",
    "        self.batch_size = 100\n",
    "        self.z_dim = 100\n",
    "        self.input_size = 28\n",
    "        \n",
    "        self.dataset = 'MNIST'\n",
    "        self.save_dir = 'models/'\n",
    "        self.result_dir = 'results/'\n",
    "        self.model_name = 'BasicModel'\n",
    "        \n",
    "        trans = transforms.Compose(\n",
    "            [transforms.Resize((self.input_size, self.input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.1307, ), std = (0.3081,))\n",
    "            ])\n",
    "                \n",
    "        self.data_loader = torch.utils.data.DataLoader(\n",
    "               datasets.MNIST(root = './data', train=True, download = True, transform = trans), \n",
    "               batch_size = self.batch_size, \n",
    "               shuffle = True)\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "        \n",
    "        self.num_batches = len(data_loader)\n",
    "        \n",
    "        #Change out_dim when I make networks use convolutions\n",
    "        self.G = GeneratorNet(in_dim = self.z_dim, out_dim = data.shape[1], input_size = self.input_size)\n",
    "        self.D = DiscriminatorNet(in_dim = data.shape[1], out_dim = 1, input_size = self.input_size)\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=0.0002)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=0.0002)\n",
    "        \n",
    "        self.BCE_loss = nn.BCELoss()\n",
    "        \n",
    "        self.sample_z = torch.rand((self.batch_size, self.z_dim))\n",
    "        \n",
    "        if self.gpu_mode:\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "            self.BCE_loss = nn.BCELoss().cuda()\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "            \n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['per_epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "        \n",
    "        self.y_real = torch.ones(self.batch_size, 1)\n",
    "        self.y_fake = torch.zeros(self.batch_size, 1)\n",
    "        \n",
    "        if self.gpu_mode:\n",
    "            self.y_real, self.y_fake = Variable(self.y_real.cuda()), Variable(self.y_fake.cuda())\n",
    "            \n",
    "        start_time = time.time()\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epoch):\n",
    "            \n",
    "            self.G.train()\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            for iter, (x, _) in enumerate(data_loader):\n",
    "                \n",
    "                z = torch.rand((self.batch_size, self.z_dim))\n",
    "                \n",
    "                if self.gpu_mode:\n",
    "                    x, z = Variable(x.cuda()), Variable(z.cuda())\n",
    "                \n",
    "                #First train D on real and fake samples\n",
    "                self.D_optimizer.zero_grad()\n",
    "                D_real = self.D(x)\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real)\n",
    "                \n",
    "                gen_ims = self.G(z)\n",
    "                D_fake = self.D(gen_ims)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake)\n",
    "                \n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "                \n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "                \n",
    "                #Now train G\n",
    "                self.G_optimizer.zero_grad()\n",
    "                \n",
    "                z = torch.rand((self.batch_size, self.z_dim))\n",
    "                if self.gpu_mode:\n",
    "                    z = Variable(z.cuda())\n",
    "                \n",
    "                gen_ims = self.G(z)\n",
    "                D_fake = self.D(gen_ims)\n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real)\n",
    "                \n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "                \n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "                \n",
    "                self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
    "            \n",
    "            self.train_hist['total_time'].append(time.time() - start_time)\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "            print(\"Completed epoch {}\".format(epoch+1))\n",
    "                \n",
    "        print(\"Done Training!\")\n",
    "        self.save()\n",
    "        \n",
    "        \n",
    "        generate_animation('{}/{}/{}/{}'.format(self.result_dir, self.dataset, self.model_name, self.model_name),\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        \n",
    "    def visualize_results(self, epoch, fix=True):\n",
    "        self.G.eval()\n",
    "        \n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "            \n",
    "        tot_num_samples = min(self.sample_num, self.batch_size)\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "        \n",
    "        samples = self.G(self.sample_z)\n",
    "#         samples = vectors_to_images(samples)\n",
    "        \n",
    "        if self.gpu_mode:\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "            \n",
    "        samples = (samples + 1)/2\n",
    "        \n",
    "        \n",
    "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], \n",
    "                    [image_frame_dim, image_frame_dim],\n",
    "        '{}/{}/{}/{}_epoch{:03}.png'.format(self.result_dir, self.dataset, self.model_name, self.model_name, epoch))\n",
    "        \n",
    "    \n",
    "    def save(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
    "        \n",
    "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.train_hist, f)\n",
    "    \n",
    "    def load(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "        \n",
    "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 1\n",
      "Completed epoch 2\n",
      "Completed epoch 3\n",
      "Completed epoch 4\n",
      "Completed epoch 5\n",
      "Completed epoch 6\n",
      "Completed epoch 7\n",
      "Completed epoch 8\n",
      "Completed epoch 9\n",
      "Completed epoch 10\n",
      "Completed epoch 11\n",
      "Completed epoch 12\n",
      "Completed epoch 13\n",
      "Completed epoch 14\n",
      "Completed epoch 15\n",
      "Completed epoch 16\n",
      "Completed epoch 17\n",
      "Completed epoch 18\n",
      "Completed epoch 19\n",
      "Completed epoch 20\n",
      "Completed epoch 21\n",
      "Completed epoch 22\n",
      "Completed epoch 23\n",
      "Completed epoch 24\n",
      "Completed epoch 25\n",
      "Completed epoch 26\n",
      "Completed epoch 27\n",
      "Completed epoch 28\n",
      "Completed epoch 29\n",
      "Completed epoch 30\n",
      "Completed epoch 31\n",
      "Completed epoch 32\n",
      "Completed epoch 33\n",
      "Completed epoch 34\n",
      "Completed epoch 35\n",
      "Completed epoch 36\n",
      "Completed epoch 37\n",
      "Completed epoch 38\n",
      "Completed epoch 39\n",
      "Completed epoch 40\n",
      "Completed epoch 41\n",
      "Completed epoch 42\n",
      "Completed epoch 43\n",
      "Completed epoch 44\n",
      "Completed epoch 45\n",
      "Completed epoch 46\n",
      "Completed epoch 47\n",
      "Completed epoch 48\n",
      "Completed epoch 49\n",
      "Completed epoch 50\n",
      "Completed epoch 51\n",
      "Completed epoch 52\n",
      "Completed epoch 53\n",
      "Completed epoch 54\n",
      "Completed epoch 55\n",
      "Completed epoch 56\n",
      "Completed epoch 57\n",
      "Completed epoch 58\n",
      "Completed epoch 59\n",
      "Completed epoch 60\n",
      "Completed epoch 61\n",
      "Completed epoch 62\n",
      "Completed epoch 63\n",
      "Completed epoch 64\n",
      "Completed epoch 65\n",
      "Completed epoch 66\n",
      "Completed epoch 67\n",
      "Completed epoch 68\n",
      "Completed epoch 69\n",
      "Completed epoch 70\n",
      "Completed epoch 71\n",
      "Completed epoch 72\n",
      "Completed epoch 73\n",
      "Completed epoch 74\n",
      "Completed epoch 75\n",
      "Completed epoch 76\n",
      "Completed epoch 77\n",
      "Completed epoch 78\n",
      "Completed epoch 79\n",
      "Completed epoch 80\n",
      "Completed epoch 81\n",
      "Completed epoch 82\n",
      "Completed epoch 83\n",
      "Completed epoch 84\n",
      "Completed epoch 85\n",
      "Completed epoch 86\n",
      "Completed epoch 87\n",
      "Completed epoch 88\n",
      "Completed epoch 89\n",
      "Completed epoch 90\n",
      "Completed epoch 91\n",
      "Completed epoch 92\n",
      "Completed epoch 93\n",
      "Completed epoch 94\n",
      "Completed epoch 95\n",
      "Completed epoch 96\n",
      "Completed epoch 97\n",
      "Completed epoch 98\n",
      "Completed epoch 99\n",
      "Completed epoch 100\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "my_GAN = GAN()\n",
    "my_GAN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_GAN.sample_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.68210436105728"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_GAN.train_hist['per_epoch_time'][-1]/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below stuff is OBSOLETE. Consolidated into GAN class + added the GPU integration.\n",
    "\n",
    "Keeping for now while ensuring above is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    N = real_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_real = discriminator(real_data)\n",
    "    err_real = loss(pred_real, ones_target(N))\n",
    "    err_real.backward()\n",
    "    \n",
    "    pred_fake = discriminator(fake_data)\n",
    "    err_fake = loss(pred_fake, zeros_target(N))\n",
    "    err_fake.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return err_real + err_fake, pred_real, pred_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data):\n",
    "    N = fake_data.size(0)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    pred = discriminator(fake_data)\n",
    "    err = loss(pred, ones_target(N))\n",
    "    err.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "\n",
    "if GPU:\n",
    "    loss = loss.cuda()\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    test_noise = test_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, (real_batch, _) in enumerate(data_loader):\n",
    "        N = real_batch.size(0)\n",
    "        \n",
    "        real_data = Variable(images_to_vectors(real_batch))\n",
    "        fake_data = generator(noise(N).cuda()).detach()\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, real_data, fake_data)\n",
    "        \n",
    "        fake_data = generator(noise(N))\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        \n",
    "        if (n_batch)%100 == 0:\n",
    "            test_images = vectors_to_images(generator(test_noise))\n",
    "            test_images = test_images.data\n",
    "    print(\"Epoch:{} \\t Time: {}\".format(epoch, time.time() - start))\n",
    "\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda:0')\n",
    "\n",
    "torch.cuda.current_device()\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
